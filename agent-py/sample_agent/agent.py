"""
ç®€åŒ–ç‰ˆæœç´¢æ™ºèƒ½ä½“ - ä½¿ç”¨MCP Tavily APIæ‰§è¡Œæœç´¢æŸ¥è¯¢
é‡‡ç”¨å®šåˆ¶çš„CopilotKitStateçŠ¶æ€ç®¡ç†
"""
import asyncio
import os
import requests
import logging
import time
import uuid
from typing_extensions import Literal
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, AIMessage
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, END
from langgraph.types import Command
from langgraph.checkpoint.memory import MemorySaver
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_core.tools import tool
from copilotkit import CopilotKitState
from langgraph.types import interrupt 
import json
import random

from langgraph.graph import MessagesState

# é…ç½®æ—¥å¿—è®°å½•
logger = logging.getLogger("agent")
if not logger.handlers:
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler("agent.log"),
            logging.StreamHandler()
        ]
    )

# å·¥å…·è°ƒç”¨è¿½è¸ª
tool_calls_tracker = {}
    
class AgentState(CopilotKitState):
    """
    å®šåˆ¶çš„AgentçŠ¶æ€ç±»
    ç»§æ‰¿è‡ªCopilotKitStateï¼Œè·å¾—CopilotKitçš„æ‰€æœ‰çŠ¶æ€å­—æ®µ
    åŒæ—¶æ·»åŠ è‡ªå®šä¹‰å­—æ®µç”¨äºæ‰©å±•åŠŸèƒ½
    """
    # è‡ªå®šä¹‰çŠ¶æ€å­—æ®µ
    proverbs: list[str] = []        # è°šè¯­åˆ—è¡¨ï¼ˆæ¥è‡ªagent_old.pyï¼‰
    search_history: list[str] = []  # æœç´¢å†å²è®°å½•
    
    # å®¡æ ¸ç›¸å…³å­—æ®µ
    approval_status: str = "none"   # å®¡æ ¸çŠ¶æ€

@tool
def get_weather(location: str):
    """
    ä½¿ç”¨è¯¥å·¥å…·è·å–æŒ‡å®šä½ç½®çš„å¤©æ°”ä¿¡æ¯
    
    Args:
        location: åœ°ç‚¹åç§°ï¼Œå¦‚"åŒ—äº¬"ã€"ä¸Šæµ·"ç­‰
        
    Returns:
        str: å¤©æ°”ä¿¡æ¯æè¿°
    """
    
    # æ¨¡æ‹Ÿå¤©æ°”æ•°æ®
    weather_conditions = ["æ™´æœ—", "å¤šäº‘", "é˜´å¤©", "å°é›¨", "å¤§é›¨", "é›·é˜µé›¨", "å°é›ª", "å¤§é›ª"]
    temp = round(random.uniform(5, 35), 1)
    humidity = random.randint(30, 95)
    wind_speed = round(random.uniform(0, 10), 1)
    wind_direction = random.choice(["ä¸œ", "å—", "è¥¿", "åŒ—", "ä¸œåŒ—", "è¥¿åŒ—", "ä¸œå—", "è¥¿å—"])
    
    # æ„å»ºJSONæ ¼å¼çš„å¤©æ°”æ•°æ®
    weather_data = {
        "location": location,
        "condition": random.choice(weather_conditions),
        "temperature": temp,
        "humidity": humidity,
        "wind": {
            "speed": wind_speed,
            "direction": wind_direction
        },
        "updated_at": "2023-06-15 14:30"
    }
    
    result = json.dumps(weather_data, ensure_ascii=False)
    logger.info(f"å¤©æ°”æŸ¥è¯¢ç»“æœ: {result[:100]}...")
    return result

# å…¨å±€å·¥å…·å˜é‡ï¼Œé¿å…é‡å¤åˆå§‹åŒ–
_all_tools = None

async def get_all_tools():
    """
    ç»Ÿä¸€çš„å·¥å…·å‡†å¤‡å‡½æ•°ï¼Œé¿å…é‡å¤åˆå§‹åŒ–MCPå®¢æˆ·ç«¯
    
    Returns:
        list: åŒ…å«æ‰€æœ‰å¯ç”¨å·¥å…·çš„åˆ—è¡¨
    """
    global _all_tools
    
    # å¦‚æœå·²ç»åˆå§‹åŒ–è¿‡ï¼Œç›´æ¥è¿”å›
    if _all_tools is not None:
        return _all_tools
    
    # åˆ›å»ºMCPå®¢æˆ·ç«¯ä»¥è·å–æœç´¢å·¥å…·
    try:
        client = MultiServerMCPClient(
            {
                "tavily-mcp": {
                    "command": "npx",
                    "args": ["-y", "tavily-mcp"],
                    "env": {**os.environ},
                    "transport": "stdio"
                }
            }
        )
        
        # è·å–MCPå·¥å…·
        mcp_tools = await client.get_tools()
        _all_tools = mcp_tools + [get_weather]
        logger.info(f"å·¥å…·åˆå§‹åŒ–æˆåŠŸï¼Œå¯ç”¨å·¥å…·: {[tool.name for tool in _all_tools]}")
        
    except Exception as e:
        logger.warning(f"âš ï¸ MCPå·¥å…·åˆå§‹åŒ–å¤±è´¥: {e}")
        # å¦‚æœMCPå·¥å…·å¤±è´¥ï¼Œåªä½¿ç”¨é‚®ä»¶å·¥å…·
        _all_tools = [get_weather]
        logger.info(f"ä½¿ç”¨å¤‡ç”¨å·¥å…·: {[tool.name for tool in _all_tools]}")
    
    return _all_tools

async def chat_node(state: AgentState, config: RunnableConfig) -> Command[Literal["tool_node", "__end__"]]:
    """
    ä¸»è¦çš„èŠå¤©èŠ‚ç‚¹ï¼ŒåŸºäºReActè®¾è®¡æ¨¡å¼
    å¤„ç†ä»¥ä¸‹åŠŸèƒ½:
    - æ¨¡å‹é…ç½®å’Œå·¥å…·ç»‘å®š
    - ç³»ç»Ÿæç¤ºè®¾ç½®
    - è·å–æ¨¡å‹å“åº”
    - å¤„ç†å·¥å…·è°ƒç”¨
    """
    
    # 1. å®šä¹‰æ¨¡å‹
    model = ChatOpenAI(model="qwen-plus",
                       api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
                       )
    
    # 2. è·å–æ‰€æœ‰å·¥å…·
    all_tools = await get_all_tools()
    
    # 3. ç»‘å®šå·¥å…·åˆ°æ¨¡å‹
    model_with_tools = model.bind_tools(
        [
            *state["copilotkit"]["actions"],  # CopilotKit actions
            *all_tools,  # æˆ‘ä»¬çš„å·¥å…·
        ],
        # ç¦ç”¨å¹¶è¡Œå·¥å…·è°ƒç”¨ä»¥é¿å…ç«äº‰æ¡ä»¶
        parallel_tool_calls=False,
    )
    
    # 4. å®šä¹‰ç³»ç»Ÿæ¶ˆæ¯
    system_message = SystemMessage(
        content=f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå…·å¤‡æœç´¢å’Œé‚®ä»¶å‘é€åŠŸèƒ½ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ã€‚
        
å½“å‰çŠ¶æ€ä¿¡æ¯:
- è°šè¯­æ”¶è—: {len(state.get('proverbs', []))}æ¡è°šè¯­
- æœç´¢å†å²: {len(state.get('search_history', []))}æ¬¡æœç´¢

å¦‚æœç”¨æˆ·æåˆ°è°šè¯­æˆ–æ ¼è¨€ï¼Œä½ å¯ä»¥å°†æœ‰ä»·å€¼çš„è°šè¯­æ·»åŠ åˆ°æ”¶è—ä¸­ã€‚
å¦‚æœéœ€è¦ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯ï¼Œè¯·ç›´æ¥è¯¢é—®ï¼Œä¸è¦è¿”å›JSONæ ¼å¼ã€‚
"""
    )
    
    # 5. è¿è¡Œæ¨¡å‹ç”Ÿæˆå“åº”

    # æ‰“å°å½“å‰å†å²æ¶ˆæ¯ä»¥ä¾›è°ƒè¯•
    print("å½“å‰å†å²æ¶ˆæ¯1:")
    print(state["messages"])
    
    response = await model_with_tools.ainvoke([
        system_message,
        *state["messages"],
    ], config)
    
    # 6. æ£€æŸ¥å“åº”ä¸­çš„å·¥å…·è°ƒç”¨
    if isinstance(response, AIMessage) and response.tool_calls:
        actions = state["copilotkit"]["actions"]
        #actions =[]
        # 6.1 æ£€æŸ¥æ˜¯å¦æœ‰éCopilotKitçš„å·¥å…·è°ƒç”¨
        if not any(
            action.get("name") == response.tool_calls[0].get("name")
            for action in actions
        ):
            # æ›´æ–°çŠ¶æ€ä¿¡æ¯
            updated_state = {"messages": response}
            
            # å¦‚æœæ˜¯æœç´¢å·¥å…·ï¼Œæ›´æ–°æœç´¢å†å²
            if response.tool_calls[0].get("name") in ["tavily-search", "tavily-extract", "tavily-crawl"]:
                search_history = state.get("search_history", [])
                search_query = response.tool_calls[0].get("args", {})

                logger.info(f"ğŸ” æ·»åŠ æœç´¢æŸ¥è¯¢åˆ°å†å²: {search_query}")
                print(f"ğŸ” æ·»åŠ æœç´¢æŸ¥è¯¢åˆ°å†å²: {search_query}")
                search_history.append(search_query["query"])
                updated_state["search_history"] = search_history
            
            return Command(goto="tool_node", update=updated_state)
    
    # 7. æ‰€æœ‰å·¥å…·è°ƒç”¨å·²å¤„ç†ï¼Œç»“æŸå¯¹è¯
    return Command(
        goto=END,
        update={"messages": response}
    )

async def tool_node(state: AgentState, config: RunnableConfig) -> Command[Literal["chat_node"]]:

    print('*****************è¿›å…¥ tool_node *****************')
    
    print("å½“å‰å†å²æ¶ˆæ¯2:")
    print(state["messages"])
    """
    è‡ªå®šä¹‰å·¥å…·è°ƒç”¨èŠ‚ç‚¹ï¼Œæ›¿ä»£å†…ç½®çš„ToolNode
    å¤„ç†å·¥å…·è°ƒç”¨å¹¶è¿”å›ç»“æœï¼ŒåŒ…å«ç®€åŒ–çš„äººå·¥å®¡æ ¸æµç¨‹
    """
    # è·å–æœ€åä¸€æ¡æ¶ˆæ¯
    last_message = state["messages"][-1]
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
    if not isinstance(last_message, AIMessage) or not last_message.tool_calls:
        logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å·¥å…·è°ƒç”¨")
        return Command(goto="chat_node", update={})
        
    # åªå¤„ç†ç¬¬ä¸€ä¸ªå·¥å…·è°ƒç”¨
    tool_call = last_message.tool_calls[0]
    
    # åˆ›å»ºç»“æ„åŒ–çš„å®¡æ ¸æ¶ˆæ¯
    approval_request = {
        "type": "tool_approval_request",
        "tool_name": tool_call.get("name"),
        "tool_args": tool_call.get("args", {}),
        "tool_id": tool_call.get("id"),
        "timestamp": "2025-07-08",
        "instructions": {
            "approve": "è¾“å…¥ 'approve' æˆ– 'é€šè¿‡' æ¥æ‰¹å‡†æ­¤å·¥å…·è°ƒç”¨",
            "reject": "è¾“å…¥ 'reject' æˆ– 'æ‹’ç»' æ¥æ‹’ç»æ­¤å·¥å…·è°ƒç”¨"
        }
    }
    
    # ä½¿ç”¨interruptç­‰å¾…ç”¨æˆ·å®¡æ ¸å†³å®š
    #approve_status = state["approval_status"]
    approve_status = 'approve'
    if(approve_status == "none"):
        approve_status = interrupt(approval_request)
    
    if approve_status in ["rejected", "reject"]:
        logger.info("âŒ å·¥å…·è°ƒç”¨è¢«æ‹’ç»")
        
        from langchain_core.messages import ToolMessage
        rejection_message = ToolMessage(
            content="å·¥å…·è°ƒç”¨è¢«ç”¨æˆ·æ‹’ç»æ‰§è¡Œã€‚",
            tool_call_id=last_message.tool_calls[0].get("id"),
            name=last_message.tool_calls[0].get("name")
        )
        
        # é‡ç½®å®¡æ ¸çŠ¶æ€
        return Command(
            goto="chat_node",
            update={
                "messages": [rejection_message],
                "approval_status": "none",  # é‡ç½®å®¡æ ¸çŠ¶æ€
            }
        )
    
    # å¦‚æœå®¡æ ¸é€šè¿‡ï¼Œæ‰§è¡Œå·¥å…·è°ƒç”¨
    elif approve_status in ["approved", "approve"]:
        logger.info("âœ… å·¥å…·è°ƒç”¨å·²è·å¾—å®¡æ ¸é€šè¿‡ï¼Œå¼€å§‹æ‰§è¡Œ")
        
        # è·å–æ‰€æœ‰å¯ç”¨å·¥å…·
        all_tools = await get_all_tools()
        
        # åˆ›å»ºå·¥å…·åç§°åˆ°å·¥å…·å‡½æ•°çš„æ˜ å°„
        tool_map = {tool.name: tool for tool in all_tools}
        
        # è·å–å¾…å®¡æ ¸çš„å·¥å…·è°ƒç”¨ä¿¡æ¯
        tool_call = last_message.tool_calls[0]
        pending_calls = [{
            "name": tool_call.get("name"),
            "args": tool_call.get("args", {}),
            "id": tool_call.get("id")
        }]
        
        # å¤„ç†å•ä¸ªå·¥å…·è°ƒç”¨
        tool_call_info = pending_calls[0]  # åªå¤„ç†ç¬¬ä¸€ä¸ªå·¥å…·è°ƒç”¨
        tool_name = tool_call_info.get("name")
        tool_args = tool_call_info.get("args", {})
        tool_id = tool_call_info.get("id")
        
        logger.info(f"ğŸ”§ æ‰§è¡Œå·²å®¡æ ¸çš„å·¥å…·: {tool_name}")
        logger.info(f"ğŸ“ å‚æ•°: {tool_args}")
        
        if tool_name in tool_map:
            try:
                # è°ƒç”¨å·¥å…·å‡½æ•°
                tool_func = tool_map[tool_name]
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºLangChainå·¥å…·(æœ‰.funcå±æ€§)
                if hasattr(tool_func, 'func') and callable(tool_func.func):
                    # è¿™æ˜¯æˆ‘ä»¬è‡ªå®šä¹‰çš„å·¥å…·(å¦‚get_weather)
                    if asyncio.iscoroutinefunction(tool_func.func):
                        result = await tool_func.func(**tool_args)
                    else:
                        result = tool_func.func(**tool_args)
                elif hasattr(tool_func, 'ainvoke'):
                    # è¿™æ˜¯MCPå·¥å…·ï¼Œä½¿ç”¨ainvokeæ–¹æ³•
                    result = await tool_func.ainvoke(tool_args)
                elif hasattr(tool_func, 'invoke'):
                    # è¿™æ˜¯MCPå·¥å…·ï¼Œä½¿ç”¨invokeæ–¹æ³•
                    result = await tool_func.invoke(tool_args)
                elif callable(tool_func):
                    # ç›´æ¥è°ƒç”¨å·¥å…·å‡½æ•°
                    if asyncio.iscoroutinefunction(tool_func):
                        result = await tool_func(**tool_args)
                    else:
                        result = tool_func(**tool_args)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„å·¥å…·ç±»å‹: {type(tool_func)}")
                
                logger.info(f"âœ… å·¥å…·è°ƒç”¨æˆåŠŸ: {str(result)[:100]}...")
                
                # åˆ›å»ºå·¥å…·ç»“æœæ¶ˆæ¯
                from langchain_core.messages import ToolMessage
                tool_message = ToolMessage(
                    content=str(result),
                    tool_call_id=tool_id,
                    name=tool_name
                )
                
            except Exception as e:
                logger.error(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                # åˆ›å»ºé”™è¯¯æ¶ˆæ¯
                from langchain_core.messages import ToolMessage
                tool_message = ToolMessage(
                    content=f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}",
                    tool_call_id=tool_id,
                    name=tool_name
                )
        else:
            logger.warning(f"âŒ æœªçŸ¥å·¥å…·: {tool_name}")
            from langchain_core.messages import ToolMessage
            tool_message = ToolMessage(
                content=f"æœªçŸ¥å·¥å…·: {tool_name}",
                tool_call_id=tool_id,
                name=tool_name
            )
        
        # é‡ç½®å®¡æ ¸çŠ¶æ€å¹¶è¿”å›å·¥å…·ç»“æœ
        return Command(
            goto="chat_node",
            update={
                "messages": [tool_message],
                "approval_status": approve_status,  # é‡ç½®å®¡æ ¸çŠ¶æ€
            }
        )
    
    # å¦‚æœçŠ¶æ€å¼‚å¸¸ï¼Œé‡ç½®çŠ¶æ€
    else:
        logger.warning(f"âš ï¸ å¼‚å¸¸çš„å®¡æ ¸çŠ¶æ€")
        return Command(
            goto="chat_node",
            update={
            }
        )

async def create_search_agent():
    """åˆ›å»ºä½¿ç”¨å®šåˆ¶çŠ¶æ€çš„æœç´¢æ™ºèƒ½ä½“
    
    Returns:
        é…ç½®å¥½çš„LangGraph StateGraph
    """
    # è·å–æ‰€æœ‰å·¥å…·ï¼ˆç”¨äºéªŒè¯å·¥å…·å¯ç”¨æ€§ï¼‰
    all_tools = await get_all_tools()
    
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(AgentState)
    workflow.add_node("chat_node", chat_node)
    workflow.add_node("tool_node", tool_node)  # ä½¿ç”¨è‡ªå®šä¹‰çš„tool_node
    workflow.set_entry_point("chat_node")
    
    # åˆ›å»ºå†…å­˜æ£€æŸ¥ç‚¹ä¿å­˜å™¨
    checkpointer = MemorySaver()
    
    # ç¼–è¯‘å¹¶è¿”å›å›¾
    agent = workflow.compile(checkpointer=checkpointer)
    return agent

# åˆ›å»ºå…¨å±€graphå®ä¾‹
graph = None

async def get_graph():
    """è·å–graphå®ä¾‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    global graph
    if graph is None:
        graph = await create_search_agent()
    return graph

# è¿è¡Œåˆå§‹åŒ–
try:
    asyncio.run(get_graph())
except Exception as e:
    logger.error(f"åˆå§‹åŒ–graphå¤±è´¥: {e}")
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„fallback graph
    workflow = StateGraph(AgentState)
    
    async def simple_chat_node(state: AgentState, config: RunnableConfig):
        model = ChatOpenAI(model="gpt-4o-mini")
        response = await model.ainvoke([
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚"),
            *state["messages"]
        ], config)
        return Command(goto=END, update={"messages": response})
    
    workflow.add_node("chat_node", simple_chat_node)
    workflow.set_entry_point("chat_node")
    checkpointer = MemorySaver()
    graph = workflow.compile(checkpointer=checkpointer)
