"""
ç®€åŒ–ç‰ˆæœç´¢æ™ºèƒ½ä½“ - ä½¿ç”¨MCP Tavily APIæ‰§è¡Œæœç´¢æŸ¥è¯¢
é‡‡ç”¨å®šåˆ¶çš„CopilotKitStateçŠ¶æ€ç®¡ç†
"""
import asyncio
import os
import requests
import logging
import time
import uuid
from typing_extensions import Literal
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, AIMessage, ToolMessage
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, END
from langgraph.types import Command
from langgraph.checkpoint.memory import MemorySaver
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_core.tools import tool
from copilotkit import CopilotKitState
from langgraph.types import interrupt 
import json
import random
from langgraph.graph import MessagesState

# é…ç½®æ—¥å¿—è®°å½•
logger = logging.getLogger("agent")
if not logger.handlers:
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler("agent.log"),
            logging.StreamHandler()
        ]
    )

# å·¥å…·è°ƒç”¨è¿½è¸ª
tool_calls_tracker = {}
    
class AgentState(CopilotKitState):
    """
    å®šåˆ¶çš„AgentçŠ¶æ€ç±»
    ç»§æ‰¿è‡ªCopilotKitStateï¼Œè·å¾—CopilotKitçš„æ‰€æœ‰çŠ¶æ€å­—æ®µ
    åŒæ—¶æ·»åŠ è‡ªå®šä¹‰å­—æ®µç”¨äºæ‰©å±•åŠŸèƒ½
    """
    # è‡ªå®šä¹‰çŠ¶æ€å­—æ®µ
    search_history: list[dict] = []  # æœç´¢å†å²è®°å½•ï¼Œæ ¼å¼: [{"query": "å…³é”®è¯", "completed": True/False, "timestamp": "æ—¶é—´æˆ³"}]


@tool
def get_weather(location: str):
    """
    ä½¿ç”¨è¯¥å·¥å…·è·å–æŒ‡å®šä½ç½®çš„å¤©æ°”ä¿¡æ¯
    
    Args:
        location: åœ°ç‚¹åç§°ï¼Œå¦‚"åŒ—äº¬"ã€"ä¸Šæµ·"ç­‰
        
    Returns:
        str: å¤©æ°”ä¿¡æ¯æè¿°
    """
    
    # æ¨¡æ‹Ÿå¤©æ°”æ•°æ®
    weather_conditions = ["æ™´æœ—", "å¤šäº‘", "é˜´å¤©", "å°é›¨", "å¤§é›¨", "é›·é˜µé›¨", "å°é›ª", "å¤§é›ª"]
    temp = round(random.uniform(5, 35), 1)
    humidity = random.randint(30, 95)
    wind_speed = round(random.uniform(0, 10), 1)
    wind_direction = random.choice(["ä¸œ", "å—", "è¥¿", "åŒ—", "ä¸œåŒ—", "è¥¿åŒ—", "ä¸œå—", "è¥¿å—"])
    
    # æ„å»ºJSONæ ¼å¼çš„å¤©æ°”æ•°æ®
    weather_data = {
        "location": location,
        "condition": random.choice(weather_conditions),
        "temperature": temp,
        "humidity": humidity,
        "wind": {
            "speed": wind_speed,
            "direction": wind_direction
        },
        "updated_at": "2023-06-15 14:30"
    }
    
    result = json.dumps(weather_data, ensure_ascii=False)
    logger.info(f"å¤©æ°”æŸ¥è¯¢ç»“æœ: {result[:100]}...")
    return result

# å…¨å±€å·¥å…·å˜é‡ï¼Œé¿å…é‡å¤åˆå§‹åŒ–
_all_tools = None

async def get_all_tools():
    """
    ç»Ÿä¸€çš„å·¥å…·å‡†å¤‡å‡½æ•°ï¼Œé¿å…é‡å¤åˆå§‹åŒ–MCPå®¢æˆ·ç«¯
    
    Returns:
        list: åŒ…å«æ‰€æœ‰å¯ç”¨å·¥å…·çš„åˆ—è¡¨
    """
    global _all_tools
    
    # å¦‚æœå·²ç»åˆå§‹åŒ–è¿‡ï¼Œç›´æ¥è¿”å›
    if _all_tools is not None:
        return _all_tools
    
    # åˆ›å»ºMCPå®¢æˆ·ç«¯ä»¥è·å–æœç´¢å·¥å…·
    try:
        client = MultiServerMCPClient(
            {
                "tavily-mcp": {
                    "command": "npx",
                    "args": ["-y", "tavily-mcp"],
                    "env": {**os.environ},
                    "transport": "stdio"
                }
            }
        )
        
        # è·å–MCPå·¥å…·
        mcp_tools = await client.get_tools()
        _all_tools = mcp_tools + [get_weather]
        logger.info(f"å·¥å…·åˆå§‹åŒ–æˆåŠŸï¼Œå¯ç”¨å·¥å…·: {[tool.name for tool in _all_tools]}")
        
    except Exception as e:
        logger.warning(f"âš ï¸ MCPå·¥å…·åˆå§‹åŒ–å¤±è´¥: {e}")
        # å¦‚æœMCPå·¥å…·å¤±è´¥ï¼Œåªä½¿ç”¨é‚®ä»¶å·¥å…·
        _all_tools = [get_weather]
        logger.info(f"ä½¿ç”¨å¤‡ç”¨å·¥å…·: {[tool.name for tool in _all_tools]}")
    
    return _all_tools

async def chat_node(state: AgentState, config: RunnableConfig):
    """
    ä¸»è¦çš„èŠå¤©èŠ‚ç‚¹ï¼ŒåŸºäºReActè®¾è®¡æ¨¡å¼
    å¤„ç†ä»¥ä¸‹åŠŸèƒ½:
    - æ¨¡å‹é…ç½®å’Œå·¥å…·ç»‘å®š
    - ç³»ç»Ÿæç¤ºè®¾ç½®
    - è·å–æ¨¡å‹å“åº”
    - å¤„ç†å·¥å…·è°ƒç”¨
    """
    
    # 1. å®šä¹‰æ¨¡å‹
    model = ChatOpenAI(model="qwen-plus",
                       api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
                       )
    
    # 2. è·å–æ‰€æœ‰å·¥å…·
    all_tools = await get_all_tools()
    
    # 3. ç»‘å®šå·¥å…·åˆ°æ¨¡å‹
    model_with_tools = model.bind_tools(
        [
            *state["copilotkit"]["actions"],  # CopilotKit actions
            *all_tools,  # æˆ‘ä»¬çš„å·¥å…·
        ],
        # ç¦ç”¨å¹¶è¡Œå·¥å…·è°ƒç”¨ä»¥é¿å…ç«äº‰æ¡ä»¶
        parallel_tool_calls=False,
    )
    
    # 4. å®šä¹‰ç³»ç»Ÿæ¶ˆæ¯
    system_message = SystemMessage(
        content=f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå…·å¤‡æœç´¢å’Œé‚®ä»¶å‘é€åŠŸèƒ½ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ã€‚
        
å½“å‰çŠ¶æ€ä¿¡æ¯:
- æœç´¢å†å²: {len(state.get('search_history', []))}æ¬¡æœç´¢

å¦‚æœéœ€è¦ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯ï¼Œè¯·ç›´æ¥è¯¢é—®ï¼Œä¸è¦è¿”å›JSONæ ¼å¼ã€‚
"""
    )
    
    # 5. è¿è¡Œæ¨¡å‹ç”Ÿæˆå“åº”
    
    response = await model_with_tools.ainvoke([
        system_message,
        *state["messages"],
    ], config)
    
    # 6. æ£€æŸ¥å“åº”ä¸­çš„å·¥å…·è°ƒç”¨
    if isinstance(response, AIMessage) and response.tool_calls:
        actions = state["copilotkit"]["actions"]
        #actions =[]
        # 6.1 æ£€æŸ¥æ˜¯å¦æœ‰éCopilotKitçš„å·¥å…·è°ƒç”¨
        if not any(
            action.get("name") == response.tool_calls[0].get("name")
            for action in actions
        ):
            # æ›´æ–°çŠ¶æ€ä¿¡æ¯
            updated_state = {"messages": response}
            
            # å¦‚æœæ˜¯æœç´¢å·¥å…·ï¼Œæ›´æ–°æœç´¢å†å² - æœç´¢å¼€å§‹é˜¶æ®µ
            if response.tool_calls[0].get("name") in ["tavily-search", "tavily-extract", "tavily-crawl"]:
                search_history = state.get("search_history", [])
                search_query = response.tool_calls[0].get("args", {})
                
                # åˆ›å»ºæœç´¢å†å²è®°å½• - å¼€å§‹æ—¶æ ‡è®°ä¸ºæœªå®Œæˆ
                search_record = {
                    "query": search_query.get("query", ""),
                    "completed": False,
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                    "tool_name": response.tool_calls[0].get("name")
                }

                logger.info(f"ğŸ” æ·»åŠ æœç´¢æŸ¥è¯¢åˆ°å†å² (å¼€å§‹): {search_record}")
                print(f"ğŸ” æ·»åŠ æœç´¢æŸ¥è¯¢åˆ°å†å² (å¼€å§‹): {search_record}")
                search_history.append(search_record)
                updated_state["search_history"] = search_history
            
            print(f"updated_state: {updated_state}")
            return updated_state
    
    # 7. æ‰€æœ‰å·¥å…·è°ƒç”¨å·²å¤„ç†ï¼Œç»“æŸå¯¹è¯
    # æ¸…ç©ºæœç´¢å†å²è®°å½•
    logger.info("ğŸ§¹ ä»»åŠ¡ç»“æŸï¼Œæ¸…ç©ºæœç´¢å†å²è®°å½•")
    return {"messages": response, "search_history": []}

async def tool_node(state: AgentState, config: RunnableConfig):

    print('*****************è¿›å…¥ tool_node *****************')
    
    print("å½“å‰å†å²æ¶ˆæ¯2:")
    print(state["messages"])
    """
    è‡ªå®šä¹‰å·¥å…·è°ƒç”¨èŠ‚ç‚¹ï¼Œæ›¿ä»£å†…ç½®çš„ToolNode
    å¤„ç†å·¥å…·è°ƒç”¨å¹¶è¿”å›ç»“æœï¼ŒåŒ…å«ç®€åŒ–çš„äººå·¥å®¡æ ¸æµç¨‹
    """
    # è·å–æœ€åä¸€æ¡æ¶ˆæ¯
    last_message = state["messages"][-1]
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
    if not isinstance(last_message, AIMessage) or not last_message.tool_calls:
        logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å·¥å…·è°ƒç”¨")
        return {}
        
    # åªå¤„ç†ç¬¬ä¸€ä¸ªå·¥å…·è°ƒç”¨
    tool_call = last_message.tool_calls[0]
    
    # åˆ›å»ºç»“æ„åŒ–çš„å®¡æ ¸æ¶ˆæ¯
    approval_request = {
        "type": "tool_approval_request",
        "tool_name": tool_call.get("name"),
        "tool_args": tool_call.get("args", {}),
        "tool_id": tool_call.get("id"),
        "timestamp": "2025-07-08"
    }
    
    # ä½¿ç”¨ç®€åŒ–çš„å®¡æ ¸æµç¨‹ - ç›´æ¥é€šè¿‡
    approve_status = interrupt(approval_request)
    
    if approve_status in ["rejected", "reject"]:
        logger.info("âŒ å·¥å…·è°ƒç”¨è¢«æ‹’ç»")
        
        rejection_message = ToolMessage(
            content="å·¥å…·è°ƒç”¨è¢«ç”¨æˆ·æ‹’ç»æ‰§è¡Œã€‚",
            tool_call_id=last_message.tool_calls[0].get("id"),
            name=last_message.tool_calls[0].get("name")
        )
        
        # é‡ç½®å®¡æ ¸çŠ¶æ€
        return {
            "messages": [rejection_message]
        }
    
    # å¦‚æœå®¡æ ¸é€šè¿‡ï¼Œæ‰§è¡Œå·¥å…·è°ƒç”¨
    elif approve_status in ["approved", "approve"]:
        logger.info("âœ… å·¥å…·è°ƒç”¨å·²è·å¾—å®¡æ ¸é€šè¿‡ï¼Œå¼€å§‹æ‰§è¡Œ")
        
        # è·å–æ‰€æœ‰å¯ç”¨å·¥å…·
        all_tools = await get_all_tools()
        
        # åˆ›å»ºå·¥å…·åç§°åˆ°å·¥å…·å‡½æ•°çš„æ˜ å°„
        tool_map = {tool.name: tool for tool in all_tools}
        
        # è·å–å¾…å®¡æ ¸çš„å·¥å…·è°ƒç”¨ä¿¡æ¯
        tool_call = last_message.tool_calls[0]
        pending_calls = [{
            "name": tool_call.get("name"),
            "args": tool_call.get("args", {}),
            "id": tool_call.get("id")
        }]
        
        # å¤„ç†å•ä¸ªå·¥å…·è°ƒç”¨
        tool_call_info = pending_calls[0]  # åªå¤„ç†ç¬¬ä¸€ä¸ªå·¥å…·è°ƒç”¨
        tool_name = tool_call_info.get("name")
        tool_args = tool_call_info.get("args", {})
        tool_id = tool_call_info.get("id")
        
        logger.info(f"ğŸ”§ æ‰§è¡Œå·²å®¡æ ¸çš„å·¥å…·: {tool_name}")
        logger.info(f"ğŸ“ å‚æ•°: {tool_args}")
        
        if tool_name in tool_map:
            try:
                # è°ƒç”¨å·¥å…·å‡½æ•°
                tool_func = tool_map[tool_name]
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºLangChainå·¥å…·(æœ‰.funcå±æ€§)
                if hasattr(tool_func, 'func') and callable(tool_func.func):
                    # è¿™æ˜¯æˆ‘ä»¬è‡ªå®šä¹‰çš„å·¥å…·(å¦‚get_weather)
                    if asyncio.iscoroutinefunction(tool_func.func):
                        result = await tool_func.func(**tool_args)
                    else:
                        result = tool_func.func(**tool_args)
                elif hasattr(tool_func, 'ainvoke'):
                    # è¿™æ˜¯MCPå·¥å…·ï¼Œä½¿ç”¨ainvokeæ–¹æ³•
                    result = await tool_func.ainvoke(tool_args)
                elif hasattr(tool_func, 'invoke'):
                    # è¿™æ˜¯MCPå·¥å…·ï¼Œä½¿ç”¨invokeæ–¹æ³•
                    result = await tool_func.invoke(tool_args)
                elif callable(tool_func):
                    # ç›´æ¥è°ƒç”¨å·¥å…·å‡½æ•°
                    if asyncio.iscoroutinefunction(tool_func):
                        result = await tool_func(**tool_args)
                    else:
                        result = tool_func(**tool_args)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„å·¥å…·ç±»å‹: {type(tool_func)}")
                
                logger.info(f"âœ… å·¥å…·è°ƒç”¨æˆåŠŸ: {str(result)[:100]}...")
                
                # åˆ›å»ºå·¥å…·ç»“æœæ¶ˆæ¯
                tool_message = ToolMessage(
                    content=str(result),
                    tool_call_id=tool_id,
                    name=tool_name
                )
                
                # å¦‚æœæ˜¯æœç´¢å·¥å…·ï¼Œæ ‡è®°æœç´¢ä¸ºå®ŒæˆçŠ¶æ€
                updated_state = {"messages": [tool_message]}
                if tool_name in ["tavily-search", "tavily-extract", "tavily-crawl"]:
                    search_history = state.get("search_history", [])
                    # æ‰¾åˆ°æœ€è¿‘çš„æœªå®Œæˆæœç´¢è®°å½•å¹¶æ ‡è®°ä¸ºå®Œæˆ
                    for record in reversed(search_history):
                        if not record.get("completed", True) and record.get("tool_name") == tool_name:
                            record["completed"] = True
                            record["completed_at"] = time.strftime("%Y-%m-%d %H:%M:%S")
                            logger.info(f"âœ… æ ‡è®°æœç´¢ä¸ºå®Œæˆ: {record['query']}")
                            print(f"âœ… æ ‡è®°æœç´¢ä¸ºå®Œæˆ: {record['query']}")
                            break
                    updated_state["search_history"] = search_history
                
            except Exception as e:
                logger.error(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                # åˆ›å»ºé”™è¯¯æ¶ˆæ¯
                tool_message = ToolMessage(
                    content=f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}",
                    tool_call_id=tool_id,
                    name=tool_name
                )
        else:
            logger.warning(f"âŒ æœªçŸ¥å·¥å…·: {tool_name}")
            tool_message = ToolMessage(
                content=f"æœªçŸ¥å·¥å…·: {tool_name}",
                tool_call_id=tool_id,
                name=tool_name
            )
        
        # é‡ç½®å®¡æ ¸çŠ¶æ€å¹¶è¿”å›å·¥å…·ç»“æœ
        return updated_state
    
    # å¦‚æœçŠ¶æ€å¼‚å¸¸ï¼Œé‡ç½®çŠ¶æ€
    else:
        logger.warning(f"âš ï¸ å¼‚å¸¸çš„å®¡æ ¸çŠ¶æ€")
        return {}

async def create_search_agent():
    """åˆ›å»ºä½¿ç”¨å®šåˆ¶çŠ¶æ€çš„æœç´¢æ™ºèƒ½ä½“
    
    Returns:
        é…ç½®å¥½çš„LangGraph StateGraph
    """
    # è·å–æ‰€æœ‰å·¥å…·ï¼ˆç”¨äºéªŒè¯å·¥å…·å¯ç”¨æ€§ï¼‰
    all_tools = await get_all_tools()
    
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(AgentState)
    workflow.add_node("chat_node", chat_node)
    workflow.add_node("tool_node", tool_node)  # ä½¿ç”¨è‡ªå®šä¹‰çš„tool_node
    workflow.set_entry_point("chat_node")
    
    # æ·»åŠ æ¡ä»¶è¾¹ç¼˜
    def should_continue(state: AgentState):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»§ç»­åˆ°å·¥å…·èŠ‚ç‚¹"""
        last_message = state["messages"][-1]
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            return "tool_node"
        return END
    
    workflow.add_conditional_edges(
        "chat_node",
        should_continue,
        {
            "tool_node": "tool_node",
            END: END
        }
    )
    
    # ä»å·¥å…·èŠ‚ç‚¹å›åˆ°èŠå¤©èŠ‚ç‚¹
    workflow.add_edge("tool_node", "chat_node")
    
    # åˆ›å»ºå†…å­˜æ£€æŸ¥ç‚¹ä¿å­˜å™¨
    checkpointer = MemorySaver()
    
    # ç¼–è¯‘å¹¶è¿”å›å›¾
    agent = workflow.compile(checkpointer=checkpointer)
    return agent

# åˆ›å»ºå…¨å±€graphå®ä¾‹
graph = None

async def get_graph():
    """è·å–graphå®ä¾‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    print("æ­£åœ¨è·å–æˆ–åˆ›å»ºæœç´¢æ™ºèƒ½ä½“...")
    global graph
    if graph is None:
        graph = await create_search_agent()
    return graph

# åˆ›å»ºå…¨å±€graphå®ä¾‹
graph = None

async def get_graph():
    """è·å–graphå®ä¾‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    global graph
    if graph is None:
        graph = await create_search_agent()
    return graph

# è¿è¡Œåˆå§‹åŒ–
try:
    print("æ­£åœ¨åˆå§‹åŒ–graph...")
    asyncio.run(get_graph())
except Exception as e:
    print(f"åˆå§‹åŒ–graphå¤±è´¥: {e}")
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„fallback graph
    workflow = StateGraph(AgentState)
    
    async def simple_chat_node(state: AgentState, config: RunnableConfig):
        model = ChatOpenAI(model="gpt-4o-mini")
        response = await model.ainvoke([
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚"),
            *state["messages"]
        ], config)
        return Command(goto=END, update={"messages": response})
    
    workflow.add_node("chat_node", simple_chat_node)
    workflow.set_entry_point("chat_node")
    checkpointer = MemorySaver()
    graph = workflow.compile(checkpointer=checkpointer)
